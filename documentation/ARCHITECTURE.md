# ARCHITECTURE

## List of main technologies:
* NodeJs
* GraphQL
* REST
* PostgreSQL
* REDIS
* RabbitMq

## Entities list
* Users (Myself as a user state: user + auth token)
* Posts (Publications, reposts, etc.)
* Comments
* Organizations (communities)
* Tags
* Blockchain nodes - for caching blockchain state


## Entities states (response fields structure):
* `Full` - all possible fields
* `Preview` - amount of fields required for lists of entities
* `Card` - minimum amount of fields, used in `object inside object` situations, 
ex. `entity_for` - for whom post is published, User or Organization data.

It is possible that in future such states will completely be moved to frontend. Because of GraphQL implementation.

## Statistics module

### Goals:
* Event-based model. Save as more as possible raw data.
* Never delete any data in order to be able to make retrospective research and compare old values of old algorithm
and new values of new calculation algorithm.
* Easy and quick access to entity current stats values to show on website pages.


### Solutions

#### Database architecture

There is a table entity_event_param which is used to store `statistics events`. Examples of such events:
* saving of entity current parameter (current importance, current upvotes amount, etc.)
* calculation of entity parameter (importance delta for current value and value before 24 hours, etc.)

Notes:
* There are no any updates. Possible operations are inserts/selects.
* There is a relational database, same as main database (PostgreSQL). It is not required yet to implement such solutions
as ClickHouse, because required period of updating is `1 hour`.
* Statistics events are completely separated from `users activity` - another kinds of events, generated by user.
Statistic event - is event only about some values.
* json_value field contains all stats values, related values, calculation description, full formula, etc. This is about
a principle `as much information as possible`. In future it will be possible to analyze effectiveness of different
calculation algorithms.
* There are `entity current params` tables, like `posts_current_params`. It has one-to-one relation with related entity
(`posts`). This is required to decrease amount of locks caused by frequent updates.

Scaling strategy:
* This table is placed to separate database in order to move this database to separate DB server in future.
* Partitioning for `hot values` (required for calculation).
* Sharding for `cold values` (required for retrospective.
* Migration to ClickHouse using existing Db schema.


#### Workers

Now there are cron-like workers only. In future it is possible to use queue-like workers (event-based, not schedule-based ones)

There are different kinds of workers:
* External data worker (ex. importance worker) - this worker fetches data from external sources (ex. blockchain)
and saves data to database, at most to `entity_event_params`. (But not always due to existing legacy solutions)
* Internal data worker - this worker fetches data from internal sources (main relational database) and saves it
to `entity_event_param`. Example - fetch current upvotes and save it.
* Worker-calculator - it uses only `entity_event_param` data to calculate new values. Example - calculate importance
delta.
* Worker-saver - it is used to save current entity stats values to concrete entity tables. For example, update (here update is appeared)
current importance delta for the concrete post. In order to use this value to select posts lists ordered by importance delta
(frontend application is a client for such request). Sometimes it is better to save such values by `worker-calculator`,
because it has all required values.


#### Code implementation

**Goal**: it should be very easy to add new parameters to stats.

**Main codebase solution:**
* Required parameter and related parameters are declared with help of special objects with appropriate Typescript interfaces.
Here is an [example for deltas calculations for posts](../lib/stats/job-params/posts-job-params.ts)
* There are different classes-jobs to save current parameters ([example for posts](../lib/stats/job/posts-stats-job.ts)).
In future these classes will be refactored to split declaration and implementation.

**Autotests codebase solution:**
* Before-after-delta parameters sets are generated randomly for every tested parameter. [Reference to generator](../test/generators/entity/entity-event-param-generator-v2.ts)

* [StatsHelper](../test/integration/helpers/stats-helper.ts) has a collection of expected field structure separated from main codebase - it is by design. It is required
to code expected values before implement the solution (TDD principle). If somebody occasionally changes implementation - autotest will fall.
* There is an universal `StatsHelper` parameters checker, based on `expected set` declared manually inside autotests.
* Here is [an example of test suite for posts](../test/integration/stats/stats-only-orgs.test.ts) 