# ARCHITECTURE

Table of contents
* [Common information](#common-information)
* [Statistics module](#statistics-module)
* [Airdrop and balances](#airdrop-and-balances)

## Common information

### List of main technologies:
* NodeJs
* GraphQL
* REST
* PostgreSQL
* REDIS
* RabbitMq

### Entities list
* Users (Myself as a user state: user + auth token)
* Posts (Publications, reposts, etc.)
* Comments
* Organizations (communities)
* Tags
* Blockchain nodes - for caching blockchain state


### Entities states (response fields structure):
* `Full` - all possible fields
* `Preview` - amount of fields required for lists of entities
* `Card` - minimum amount of fields, used in `object inside object` situations, 
ex. `entity_for` - for whom post is published, User or Organization data.

It is possible that in the future such states will completely be moved to frontend. Because of GraphQL implementation.

## Statistics module

### Goals:
* Event-based model. Save as much as possible raw data.
* Never delete any data in order to be able to make retrospective research and compare the old values of an old algorithm
and the new values of the new calculation algorithm.
* Easy and quick access to the entity current stats values to show on the website pages.


### Solutions

#### Database architecture

There is a table entity_event_param which is used to store `statistics events`. Examples of such events:
* saving of the entity current parameter (current importance, current upvotes amount, etc.)
* calculation of the entity parameter (importance delta for current value and value before 24 hours, etc.)

Notes:
* There are no updates. Possible operations are inserts/selects.
* There is a relational database, same as the main database (PostgreSQL). It is not required yet to implement such solutions
as ClickHouse, because the required period of updating is `1 hour`.
* Statistics events are completely separated from `users activity` - a different kind of events, generated by user.
Statistic event - an event only about some values.
* json_value field contains all stats values, related values, calculation description, the full formula, etc. This is about
the principle `as much information as possible`. In the future, it will be possible to analyze the effectiveness of different
calculation algorithms.
* There are `entity current params` tables, like `posts_current_params`. It has a one-to-one relation with the related entity
(`posts`). This is required to decrease the amount of locks caused by frequent updates.

Scaling strategy:
* This table is placed to separate the database in order to move this database to a separate DB server in the future.
* Partitioning for `hot values` (required for calculation).
* Sharding for `cold values` (required for retrospective).
* Migration to ClickHouse using existing the DB schema.


#### Workers

Currently there are cron-like workers only. In the future, it is possible to use queue-like workers (event-based, not the schedule-based ones).

There are different kinds of workers:
* External data worker (ex. importance worker) - this worker fetches data from external sources (ex. blockchain)
and saves data to the database, at most to `entity_event_params`. (But not always due to the existing legacy solutions)
* Internal data worker - this worker fetches data from internal sources (main relational database) and saves it
to `entity_event_param`. Example - fetch current upvotes and save it.
* Worker-calculator - it uses only `entity_event_param` data to calculate new values. Example - calculate importance
delta.
* Worker-saver - it is used to save current entity stats values to concrete entity tables. For example, update (here update is appeared)
current importance delta for the concrete post. In order to use this value to select posts, the lists are ordered by importance delta
(frontend application is a client for such request). Sometimes it is better to save such values by `worker-calculator`,
because it has all the required values.


#### Code implementation

**Goal**: it should be very easy to add new parameters to stats.

**Main codebase solution:**
* The required parameter and related parameters are declared with the help of special objects with the appropriate Typescript interfaces.
Here is an [example for deltas calculations for posts](../lib/stats/job-params/posts-job-params.ts)
* There are different classes-jobs to save current parameters ([example for posts](../lib/stats/job/posts-stats-job.ts)).
In the future, these classes will be refactored to split declaration and implementation.

**Autotests codebase solution:**
* The before-after-delta parameters sets are generated randomly for every tested parameter. [Reference to generator](../test/generators/entity/entity-event-param-generator-v2.ts)

* [StatsHelper](../test/integration/helpers/stats-helper.ts) has a collection of an expected field structure separated from the main codebase - this is by design. It is required
to code the expected values before implementing the solution (TDD principle). If somebody occasionally changes the implementation, the autotest will fail.
* There is a universal `StatsHelper` parameters checker, based on `expected set` declared manually inside autotests.
* Here is [an example of test suite for posts](../test/integration/stats/stats-only-orgs.test.ts) 

## Airdrop and balances

There are different accounts in the system to represent the balance flows:

type | description
--- | ---
`debt` | To track incoming balances, positive amount
`income` | To track incoming balances, always negative. Required to track new amounts of tokens for an airdrop (`debt` + `income` = 0) 
`reserved` | Amount of tokens user should receive in the future if everything goes ok
`waiting` | Amount of tokens represented by blockchain transaction which is already sent to blockchain
`wallet` | Current amount of airdrop tokens under user's control 


Notes:
* For every new `symbol` new balance account record should be created


### Workflow (with example numbers):

Beforehand - `debt` and `income` accounts must be created.

* There is new token distribution for airdrop, amount = 100 000 tokens (`TNS`). 
* New transaction - from `income` (- 100 000) to `debt` (100 000).
* User is asking about his airdrop state.
* User fulfills some business conditions in order to participate (ex. follows devExchange community)
* Background worker checks conditions and determines users that fulfill all conditions.
* `reserved`, `waiting` and `wallet` accounts are created.
* Transaction is created: from `debt` to `reserved`, amount = 100 TNS
* Other worker fetches `pending` users and creates blockchain transaction (trx).
* Trx is created and is sent to blockchain. Trx ID is received.
?think - what if there backend is down and no following record? - answer: check airdrop state in background
* DB transaction is created: from `reserved` to `waiting`.
* Background worker checks user's airdrop conditions.
** If success - from `waiting` to `wallet`
** If fail - rollback from `waiting` to `reserved`


### Database structure

Please observe the migrations. 
The first one is [create-tables-airdrops-and-accounts](../migrations_knex_monolith/20190320083713_create-tables-airdrops-and-accounts.js)

#### Future requests (for reference in the future)

------ Airdrop state --------

--- How to calc already distributed amounts
SELECT
    COUNT(wallet_account.current_balance) AS distributed_amount,
    users_tokens.symbol_id AS symbol_id
FROM
    users_tokens
INNER JOIN accounts AS wallet_account ON accounts.id = users_token.wallet_account_id
WHERE airdrop_id = ${airdropId}
GROUP BY users_tokens.symbol_id
